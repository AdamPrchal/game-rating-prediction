import { ImageWithCaption } from "../components/ImageWithCaption";

<article id="trenovaniModelu">
  <header style={{marginBottom: "1rem"}}>
    ##  TrÃ©novÃ¡nÃ­ modelÅ¯ ğŸ”
  </header>

### RozdÄ›lenÃ­ dat

TÄ›snÄ› pÅ™ed trenovÃ¡nÃ­m jsme dataset rozdÄ›lili na trÃ©novacÃ­ a testovacÃ­ set. RozdÄ›lenÃ­ bylo provedeno tak, aby trÃ©novacÃ­ set tvoÅ™il 80&nbsp;% z celkovÃ©ho datasetu a zbylÃ½ch 20&nbsp;% bylo vyhrazeno pro testovÃ¡nÃ­. Toto rozdÄ›lenÃ­ jsme zvolili, jelikoÅ¾ pÅ™i prÅ¯bÄ›Å¾nÃ©m manuÃ¡lnÃ­m testovÃ¡nÃ­ vracely trÃ©novanÃ© modely lepÅ¡Ã­ vÃ½sledky.

### TrÃ©novÃ¡nÃ­ modelÅ¯

KaÅ¾dÃ½ z modelÅ¯ (RandomForestClassifier, XGBClassifier a SVC) byl natrÃ©novÃ¡n na stejnÃ© trÃ©novacÃ­ sadÄ› dat. Pro kaÅ¾dÃ½ model byly nastaveny hyperparametry za pouÅ¾itÃ­ metody **GridSearchCV**, kterÃ¡ automaticky prohledÃ¡vÃ¡ prostor hyperparametrÅ¯ a hledÃ¡ tu nejlepÅ¡Ã­ kombinaci pro dosaÅ¾enÃ­ nejlepÅ¡Ã­ho vÃ½konu modelu. VÃ½slednÃ© nejlepÅ¡Ã­ kombinace hyperparametrÅ¯ pro kaÅ¾dÃ½ model nÃ¡m vyÅ¡li nÃ¡sledujÃ­cÃ­:

**RandomForestClassifier**

- `max_depth` (30): MaximÃ¡lnÃ­ hloubka stromu. Toto je maximÃ¡lnÃ­ poÄet ÃºrovnÃ­, kterÃ© mÅ¯Å¾e strom mÃ­t. OmezenÃ­ hloubky stromu by mÄ›lo pomoci pÅ™edejÃ­t pÅ™euÄenÃ­.

- `n_estimators` (120): PoÄet stromÅ¯. VÄ›tÅ¡Ã­ poÄet stromÅ¯ by mÄ›l pÅ™inÃ©st lepÅ¡Ã­ vÃ½sledky, ale takÃ© zvyÅ¡uje vÃ½poÄetnÃ­ nÃ¡roky.

**XGBClassifier**

- `learning_rate` (0.1): Rychlost, jakou model aktualizuje svÃ© pÅ™edpovÄ›di v kaÅ¾dÃ© iteraci. MalÃ¡ hodnota pÅ™inÃ¡Å¡Ã­ lepÅ¡Ã­ vÃ½sledky, ale obnaÅ¡Ã­ i vyÅ¡Å¡Ã­ nÃ¡roky na systÃ©m.

- `max_depth` (30): MaximÃ¡lnÃ­ hloubka stromu. StejnÄ› jako u RandomForestClassifier.

- `n_estimators` (100): PoÄet stromÅ¯, kterÃ© se majÃ­ vytvoÅ™it pÅ™i uÄenÃ­ modelu. StejnÄ› jako u RandomForestClassifier.

**SVC**

- `C` (10): Penalizace za Å¡patnÄ› klasifikovanÃ© body. ÄŒÃ­m vÄ›tÅ¡Ã­ `C`, tÃ­m tvrdÅ¡Ã­ je model na Å¡patnÄ› klasifikovanÃ© body.

- `gamma` (0.01): Jak moc daleko bodÅ¯ od sebe se model podÃ­vÃ¡, kdyÅ¾ se rozhoduje, jak je klasifikovat. MenÅ¡Ã­ `gamma` znamenÃ¡, Å¾e model se podÃ­vÃ¡ dÃ¡le.

### HodnocenÃ­ modelÅ¯

Po natrÃ©novÃ¡nÃ­ modelÅ¯ byly pouÅ¾ity rÅ¯znÃ© metriky pro zhodnocenÃ­ jejich vÃ½konu na testovacÃ­ sadÄ›. NÃ¡stroj scikit-learn obsahuje funkce, kterÃ© nÃ¡m umoÅ¾nili tyto metriky snadno zÃ­skat. Å lo konkrÃ©tnÄ› o metriky jako Accuracy, F-score, ROC AUC Score a Log Loss pro kaÅ¾dÃ½ z modelÅ¯. Tyto metriky nÃ¡m poskytly informace o tom, jak dobÅ™e se kaÅ¾dÃ½ model nauÄil pÅ™edpovÃ­dat cÃ­lovou promÄ›nnou.

5. **VÃ½bÄ›r nejlepÅ¡Ã­ho modelu**: Na zÃ¡kladÄ› vÃ½sledkÅ¯ hodnocenÃ­ modelÅ¯ byl jako nejlepÅ¡Ã­ model vybrÃ¡n RandomForestClassifier. Tento model dosÃ¡hl nejvyÅ¡Å¡Ã­ pÅ™esnosti (Accuracy) a nejvyÅ¡Å¡Ã­ho F-score mezi vÅ¡emi testovanÃ½mi modely.

6. **Interpretace vÃ½sledkÅ¯**: AnalÃ½za vÃ½sledkÅ¯ ukÃ¡zala, Å¾e RandomForestClassifier nejlÃ©pe pÅ™edpovÃ­dÃ¡ cÃ­lovou promÄ›nnou. Tento model vykazoval nejvyÅ¡Å¡Ã­ mÃ­ru pÅ™esnosti a F-score, coÅ¾ naznaÄuje, Å¾e mÃ¡ dobrÃ© vÃ½sledky jak v pÅ™esnosti pÅ™edpovÄ›di, tak v rovnovÃ¡ze mezi pÅ™esnostÃ­ a ÃºplnostÃ­. Na druhou stranu, SVC dosÃ¡hl nejniÅ¾Å¡Ã­ho vÃ½konu mezi testovanÃ½mi modely, coÅ¾ ukazuje, Å¾e tento model by mohl bÃ½t pro tento konkrÃ©tnÃ­ Ãºkol mÃ©nÄ› vhodnÃ½. VÃ½sledky ukazujÃ­, Å¾e vÃ½bÄ›r sprÃ¡vnÃ©ho modelu a jeho hyperparametrÅ¯ mÅ¯Å¾e mÃ­t velkÃ½ vliv na vÃ½slednÃ½ vÃ½kon pÅ™i predikci cÃ­lovÃ© promÄ›nnÃ©.

</article>
