

<article id="dataPreprocessing">
    <header style={{marginBottom: "1rem"}}>
        ## PÅ™edzpracovÃ¡nÃ­ vstupnÃ­ch dat ğŸ‘¨â€ğŸ’»
    </header>

    V tomto projektu jsme upravili naÅ¡e pÅ™Ã­stupy k pÅ™edzpracovÃ¡nÃ­ dat, aby lÃ©pe odpovÃ­daly potÅ™ebÃ¡m neuronovÃ½ch sÃ­tÃ­ a zvÃ½Å¡ily pÅ™esnost modelu.

    ### OdstranÄ›nÃ­ nepotÅ™ebnÃ½ch sloupcÅ¯ a Å™Ã¡dkÅ¯

    ZaÄali jsme odstranÄ›nÃ­m nepotÅ™ebnÃ½ch sloupcÅ¯, jako v minulÃ©m projektu, a Å™Ã¡dkÅ¯ s chybÄ›jÃ­cÃ­mi hodnotami v klÃ­ÄovÃ½ch sloupcÃ­ch.

    ### ZpracovÃ¡nÃ­ hodnocenÃ­

    Na rozdÃ­l od pÅ™edchozÃ­ho projektu jsme hodnocenÃ­ her ponechali v desetinnÃ© formÄ›, protoÅ¾e jsme zjistili, Å¾e to nemÃ¡ vliv na vÃ½kon modelu.

    ### Datum vydÃ¡nÃ­
    Pro datum vydÃ¡nÃ­ jsme tentokrÃ¡t zvolili nejdÅ™Ã­vÄ›jÅ¡Ã­ datum z dostupnÃ½ch dat vydÃ¡nÃ­ a pÅ™evedli jsme je na rok, mÄ›sÃ­c a den.

    ### One hot encoding

    Pro platformy a Å¾Ã¡nry jsme pouÅ¾ili metodu one hot encoding, aby bylo moÅ¾nÃ© efektivnÄ›ji zpracovat tyto kategorickÃ© promÄ›nnÃ©.

    ### Kategorizace vÃ½vojÃ¡Å™Å¯ a vydavatelÅ¯

    VytvoÅ™ili jsme sloupce 'developer_size' a 'publisher_size', kde jsme pomocÃ­ KMeans a elbow metody urÄili optimÃ¡lnÃ­ poÄet skupin pro kategorizaci. Zjistili jsme, Å¾e nejlepÅ¡Ã­ je pouÅ¾Ã­t 2 clustery pro vydavatele a 3 pro vÃ½vojÃ¡Å™e.
    <center>
        <ImageWithCaption
            src="/neuronove-site/vydavatel.png"
            caption=""
            source={""}
        />
    </center>
    <center>
        <ImageWithCaption
            src="/neuronove-site/vyvojar.png"
            caption=""
            source={""}
        />
    </center>


    ### Normalizace dat

    Pro normalizaci jsme tentokrÃ¡t zvolili **StandardScaler** mÃ­sto MinMaxScaleru, coÅ¾ se ukÃ¡zalo jako efektivnÄ›jÅ¡Ã­ pro nÃ¡Å¡ model.

    Tyto zmÄ›ny ve zpÅ¯sobu pÅ™edzpracovÃ¡nÃ­ dat nÃ¡m pomohly pÅ™ekonat problÃ©my s nÃ¡hodnou klasifikacÃ­, kterÃ© jsme zaznamenali pÅ™i pouÅ¾itÃ­ stejnÃ½ch metod jako v pÅ™edchozÃ­m projektu.

   ### RozdÄ›lenÃ­ dat

   TÄ›snÄ› pÅ™ed trenovÃ¡nÃ­m jsme dataset rozdÄ›lili na trÃ©novacÃ­ a testovacÃ­ set. RozdÄ›lenÃ­ bylo provedeno tak, aby trÃ©novacÃ­ set tvoÅ™il 80&nbsp;% z celkovÃ©ho datasetu a zbylÃ½ch 20&nbsp;% bylo vyhrazeno pro testovÃ¡nÃ­. Toto rozdÄ›lenÃ­ jsme zvolili, jelikoÅ¾ pÅ™i prÅ¯bÄ›Å¾nÃ©m manuÃ¡lnÃ­m testovÃ¡nÃ­ vracely trÃ©novanÃ© modely lepÅ¡Ã­ vÃ½sledky.
</article>
